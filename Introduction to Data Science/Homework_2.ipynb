{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "## Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Xinmeng Li\n",
    "\n",
    "Student Netid: xl1575\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Case study (5 Points)\n",
    "- Read [this article](http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html) in the New York Times.\n",
    "- Use what we've learned in class and from the book to describe how one could set Target's problem up as a predictive modeling problem, such that they could have gotten the results that they did.  Formulate your solution as a proposed plan using our data science terminology.  Include all the aspects of the formulation that you see as relevant to solving the problem.  Be precise but concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Business/Data Understanding.<br>\n",
    "Goal: Identify pregnant women and predict their due dates. As a consequence, target can do advertising at some time points to attract more pregnant women customers and encourage them to form a new buying habit.\n",
    "Task: Build a classifier to decide a customer is pregnant or not, and use regression to predict her due date.\n",
    "Why: Because the birth of a new child is a period during which people will rebuild their buying habits.\n",
    "What Data: Personal information and buying behaviors of customer associated with a unique Guest ID.\n",
    "What constraint: Not enough information provided for resources(such as computation power) and data limit.<br>\n",
    "2. Data Preparation.<br>\n",
    "Clean the data to make it in a consistant format. One hot encoding for categorical variable. Delete rows with missing values. Normalize numerical variables.\n",
    "Filter the data to find the most informative variables, such as buying histories.\n",
    "If the dataset is large, try randomly sample it such as cross validation.\n",
    "If the dataset is unbalanced, try oversampling or undersampling.<br>\n",
    "3. Modeling<br>\n",
    "Since the birthday data is public and target can get access to the family information of customers, whether a customer used to be pregnant is known and a supervised model could be built.\n",
    "First, build a baseline. Try simple and widely used model such as logistic regression and random forest. \n",
    "Second, if the performance is not good after optimazition such as feature engineering and boosting, try other more complicated models such as neural networks.<br>\n",
    "4. Evaluation<br>\n",
    "Measure the accuracy of models by parameter like f score and AUC-ROC.\n",
    "Consider the cost, speed, memory, reliability, consistancy and interpretibility.<br>\n",
    "5. Deployment<br>\n",
    "Send corresponding offers to potentically pregnant customers predicted by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Exploring data in the command line (4 Points - 1 each)\n",
    "For this part we will be using the data file located in `\"advertising_events.csv\"`. This file consists of records that pertain to some online advertising events on a given day. There are 4 comma separated columns in this order: `userid`, `timestamp`, `domain`, and `action`. These fields are of type `int`, `int`, `string`, and `int` respectively. Answer the following questions using Linux/Unix bash commands. All questions can be answered in one line (sometimes, with pipes)! Some questions will have many possible solutions. Don't forget that in IPython notebooks you must prefix all bash commands with an exclamation point, i.e. `\"!command arguments\"`.\n",
    "\n",
    "[Hints: You can experiment with whatever you want in the notebook and then delete things to construct your answer later.  You can also use ssh to use the actual bash shell in your terminal and then just paste your answers here. Recall that once you enter the \"!\" then filename completion should work. Also, these are standard data exploration commands that are quick and easy to use in a terminal or in the notebook. We don't cover command line operations formally in this class, but these are worth learning (and thus are part of the HW). Be resourceful. Use whatever online cheat sheets or Stackoverflow to answer the question.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. How many records (lines) are in this file (look up wc)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10341 advertising_events.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "!wc -l advertising_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many unique users are in this file? (hint: consider the 'cut' command and use pipe operator '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     732\r\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "!cut -d',' -f1  advertising_events.csv| sort -u  | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Rank all domains by the number of visits they received in descending order. (hint: consider the 'cut', 'uniq' and 'sort' commands and the pipe operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3114 google.com\r\n",
      "2092 facebook.com\r\n",
      "1036 youtube.com\r\n",
      "1034 yahoo.com\r\n",
      "1022 baidu.com\r\n",
      " 513 wikipedia.org\r\n",
      " 511 amazon.com\r\n",
      " 382 qq.com\r\n",
      " 321 twitter.com\r\n",
      " 316 taobao.com\r\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "!cut -d',' -f3  advertising_events.csv| sort|uniq -c|sort -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. List all records for the user with user id 37. (hint: this can be done using 'grep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37,648061658,google.com,0\r\n",
      "37,642479972,google.com,2\r\n",
      "37,644493341,facebook.com,2\r\n",
      "37,654941318,facebook.com,1\r\n",
      "37,649979874,baidu.com,1\r\n",
      "37,653061949,yahoo.com,1\r\n",
      "37,655020469,google.com,3\r\n",
      "37,640878012,amazon.com,0\r\n",
      "37,659864136,youtube.com,1\r\n",
      "37,640361378,yahoo.com,1\r\n",
      "37,653862134,facebook.com,0\r\n",
      "37,648828970,youtube.com,0\r\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "!grep -w 37 advertising_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Dealing with data Pythonically (16 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You might find these packages useful. You may import any others you want!\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Load the data set `\"ads_dataset.tsv\"` into a Python Pandas data frame called `ads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Place your code here\n",
    "ads = pd.read_table(\"ads_dataset.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Write a Python function called `getDfSummary()` that does the following:\n",
    "- Takes as input a data frame\n",
    "- For each variable in the data frame calculates the following features:\n",
    "  - `number_nan` to count the number of missing not-a-number values\n",
    "  - Ignoring missing, NA, and Null values:\n",
    "    - `number_distinct` to count the number of distinct values a variable can take on\n",
    "    - `mean`, `max`, `min`, `std` (standard deviation), and `25%`, `50%`, `75%` to correspond to the appropriate percentiles\n",
    "- All of these new features should be loaded in a new data frame. Each row of the data frame should be a variable from the input data frame, and the columns should be the new summary features.\n",
    "- Returns this new data frame containing all of the summary information\n",
    "\n",
    "Hint: The pandas `describe()` [(manual page)](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) method returns a useful series of values that can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    # Place your code here\n",
    "    output_data = input_data.describe().drop('count').T\n",
    "    output_data['number_nan'] = list(input_data.isnull().sum(axis = 0))\n",
    "    output_data['number_distinct'] = list(input_data.nunique(dropna=True))\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. How long does it take for your `getDfSummary()` function to work on your `ads` data frame? Show us the results below.\n",
    "\n",
    "Hint: `%timeit getDfSummary(ads)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 89 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "%timeit -n 100 getDfSummary(ads) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Using the results returned from `getDfSummary()`, which fields, if any, contain missing `NaN` values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buy_freq']\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "result = getDfSummary(ads)\n",
    "print([result.index[i] for i in range(0,len(result.index)) if result['number_nan'][i]>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>number_nan</th>\n",
       "      <th>number_distinct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isbuyer</th>\n",
       "      <td>0.042632</td>\n",
       "      <td>0.202027</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_freq</th>\n",
       "      <td>1.240653</td>\n",
       "      <td>0.782228</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>52257</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_freq</th>\n",
       "      <td>1.852777</td>\n",
       "      <td>2.921820</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_interval</th>\n",
       "      <td>0.210008</td>\n",
       "      <td>3.922016</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>174.62500</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv_interval</th>\n",
       "      <td>5.825610</td>\n",
       "      <td>17.595442</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>184.91670</td>\n",
       "      <td>0</td>\n",
       "      <td>5886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_buy</th>\n",
       "      <td>-0.198040</td>\n",
       "      <td>4.997792</td>\n",
       "      <td>-181.9238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.28571</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_visit</th>\n",
       "      <td>-10.210786</td>\n",
       "      <td>31.879722</td>\n",
       "      <td>-187.6156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.40192</td>\n",
       "      <td>0</td>\n",
       "      <td>15135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_buy</th>\n",
       "      <td>64.729335</td>\n",
       "      <td>53.476658</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_visit</th>\n",
       "      <td>64.729335</td>\n",
       "      <td>53.476658</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_buy</th>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.079479</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_visit</th>\n",
       "      <td>0.277444</td>\n",
       "      <td>0.447742</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_urls</th>\n",
       "      <td>86.569343</td>\n",
       "      <td>61.969765</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>206.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_checkins</th>\n",
       "      <td>720.657592</td>\n",
       "      <td>1275.727306</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>127.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>37091.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>4628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_buy</th>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.067924</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean          std       min    25%    50%  \\\n",
       "isbuyer                0.042632     0.202027    0.0000    0.0    0.0   \n",
       "buy_freq               1.240653     0.782228    1.0000    1.0    1.0   \n",
       "visit_freq             1.852777     2.921820    0.0000    1.0    1.0   \n",
       "buy_interval           0.210008     3.922016    0.0000    0.0    0.0   \n",
       "sv_interval            5.825610    17.595442    0.0000    0.0    0.0   \n",
       "expected_time_buy     -0.198040     4.997792 -181.9238    0.0    0.0   \n",
       "expected_time_visit  -10.210786    31.879722 -187.6156    0.0    0.0   \n",
       "last_buy              64.729335    53.476658    0.0000   18.0   51.0   \n",
       "last_visit            64.729335    53.476658    0.0000   18.0   51.0   \n",
       "multiple_buy           0.006357     0.079479    0.0000    0.0    0.0   \n",
       "multiple_visit         0.277444     0.447742    0.0000    0.0    0.0   \n",
       "uniq_urls             86.569343    61.969765   -1.0000   30.0   75.0   \n",
       "num_checkins         720.657592  1275.727306    1.0000  127.0  319.0   \n",
       "y_buy                  0.004635     0.067924    0.0000    0.0    0.0   \n",
       "\n",
       "                            75%          max  number_nan  number_distinct  \n",
       "isbuyer                0.000000      1.00000           0                2  \n",
       "buy_freq               1.000000     15.00000       52257               10  \n",
       "visit_freq             2.000000     84.00000           0               64  \n",
       "buy_interval           0.000000    174.62500           0              295  \n",
       "sv_interval            0.104167    184.91670           0             5886  \n",
       "expected_time_buy      0.000000     84.28571           0              348  \n",
       "expected_time_visit    0.000000     91.40192           0            15135  \n",
       "last_buy             105.000000    188.00000           0              189  \n",
       "last_visit           105.000000    188.00000           0              189  \n",
       "multiple_buy           0.000000      1.00000           0                2  \n",
       "multiple_visit         1.000000      1.00000           0                2  \n",
       "uniq_urls            155.000000    206.00000           0              207  \n",
       "num_checkins         802.000000  37091.00000           0             4628  \n",
       "y_buy                  0.000000      1.00000           0                2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. For the fields with missing values, does it look like the data is missing at random? Are there any other fields that correlate perfectly, or predict that the data is missing? If missing, what should the data value be?\n",
    "\n",
    "Hint: create another data frame that has just the records with a missing value. Get a summary of this data frame using `getDfSummary()` and compare the differences. Do some feature distributions change dramatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Place your code here\n",
    "nanads = ads[ads.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result2 = getDfSummary(nanads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>number_nan</th>\n",
       "      <th>number_distinct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isbuyer</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52257</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_freq</th>\n",
       "      <td>1.651549</td>\n",
       "      <td>2.147955</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_interval</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv_interval</th>\n",
       "      <td>5.686388</td>\n",
       "      <td>17.623555</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>184.91670</td>\n",
       "      <td>0</td>\n",
       "      <td>5112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_buy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_visit</th>\n",
       "      <td>-9.669298</td>\n",
       "      <td>31.239030</td>\n",
       "      <td>-187.6156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.40192</td>\n",
       "      <td>0</td>\n",
       "      <td>13351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_buy</th>\n",
       "      <td>65.741317</td>\n",
       "      <td>53.484622</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_visit</th>\n",
       "      <td>65.741317</td>\n",
       "      <td>53.484622</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_buy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_visit</th>\n",
       "      <td>0.255602</td>\n",
       "      <td>0.436203</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_urls</th>\n",
       "      <td>86.656180</td>\n",
       "      <td>61.996711</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>206.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_checkins</th>\n",
       "      <td>721.848518</td>\n",
       "      <td>1284.504018</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>126.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>37091.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>4570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_buy</th>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.054904</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean          std       min    25%    50%  \\\n",
       "isbuyer                0.000000     0.000000    0.0000    0.0    0.0   \n",
       "buy_freq                    NaN          NaN       NaN    NaN    NaN   \n",
       "visit_freq             1.651549     2.147955    1.0000    1.0    1.0   \n",
       "buy_interval           0.000000     0.000000    0.0000    0.0    0.0   \n",
       "sv_interval            5.686388    17.623555    0.0000    0.0    0.0   \n",
       "expected_time_buy      0.000000     0.000000    0.0000    0.0    0.0   \n",
       "expected_time_visit   -9.669298    31.239030 -187.6156    0.0    0.0   \n",
       "last_buy              65.741317    53.484622    0.0000   19.0   52.0   \n",
       "last_visit            65.741317    53.484622    0.0000   19.0   52.0   \n",
       "multiple_buy           0.000000     0.000000    0.0000    0.0    0.0   \n",
       "multiple_visit         0.255602     0.436203    0.0000    0.0    0.0   \n",
       "uniq_urls             86.656180    61.996711   -1.0000   30.0   75.0   \n",
       "num_checkins         721.848518  1284.504018    1.0000  126.0  318.0   \n",
       "y_buy                  0.003024     0.054904    0.0000    0.0    0.0   \n",
       "\n",
       "                            75%          max  number_nan  number_distinct  \n",
       "isbuyer                0.000000      0.00000           0                1  \n",
       "buy_freq                    NaN          NaN       52257                0  \n",
       "visit_freq             2.000000     84.00000           0               48  \n",
       "buy_interval           0.000000      0.00000           0                1  \n",
       "sv_interval            0.041667    184.91670           0             5112  \n",
       "expected_time_buy      0.000000      0.00000           0                1  \n",
       "expected_time_visit    0.000000     91.40192           0            13351  \n",
       "last_buy             106.000000    188.00000           0              189  \n",
       "last_visit           106.000000    188.00000           0              189  \n",
       "multiple_buy           0.000000      0.00000           0                1  \n",
       "multiple_visit         1.000000      1.00000           0                2  \n",
       "uniq_urls            155.000000    206.00000           0              207  \n",
       "num_checkins         803.000000  37091.00000           0             4570  \n",
       "y_buy                  0.000000      1.00000           0                2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the summary table of the data with missing values, we observe that the values of number_distinct of some variables are different from the summary table of the original data. Let's do some analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find fields with number_distinct dramatically changed for the missing value table, we only select that fields whose  distinct number in the original data is greater than or equal to twice of that in the missing value data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['isbuyer', 'buy_interval', 'expected_time_buy', 'multiple_buy']\n"
     ]
    }
   ],
   "source": [
    "diff = [result.index[i] for i in range(0,len(result.index)) if result['number_distinct'][i]>=2*\n",
    "       result2['number_distinct'][i] and result.index[i]!='buy_freq']\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out values of these fields when data missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------isbuyer---------\n",
      "[0]\n",
      "---------buy_interval---------\n",
      "[ 0.]\n",
      "---------expected_time_buy---------\n",
      "[ 0.]\n",
      "---------multiple_buy---------\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "for v in diff:\n",
    "    print('---------'+v+'---------')\n",
    "    print(nanads[v].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, these for variables are always 0 for missing data. However, this cannot garantee that we can predict missing data once it has a 0 'isbuyer', 'buy_interval', 'expected_time_buy', or 'multiple_buy'. We also need to consider the probability that these fields are 0 when no value missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ads has  54584  rows\n",
      "nanads has  52257  rows\n",
      "---------isbuyer---------\n",
      "0\n",
      "0.0\n",
      "1.0\n",
      "---------buy_interval---------\n",
      "1980\n",
      "0.850880962613\n",
      "1.0\n",
      "---------expected_time_buy---------\n",
      "1980\n",
      "0.850880962613\n",
      "1.0\n",
      "---------multiple_buy---------\n",
      "1980\n",
      "0.850880962613\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print('ads has ',len(ads),' rows')\n",
    "print('nanads has ',len(nanads),' rows')\n",
    "for v in diff:\n",
    "    print('---------'+v+'---------')\n",
    "    print((ads[v] == 0).sum()-(nanads[v] == 0).sum())\n",
    "    print(((ads[v] == 0).sum()-(nanads[v] == 0).sum())/(len(ads[v])-len(nanads[v])))\n",
    "    print((nanads[v] == 0).sum()/len(nanads[v]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the data without value missing is not likely to have a 0 isbuyer, and is 85% likely to have a 0 buyer_interval, expected_time_buy, and multiple_buy. Therefore, although if a data has missing value, all of these four fields must be 0, we are not sure that if the buyer_interval, expected_time_buy, and multiple_buy of data are 0, then data must have missing value. We are confident to predict that a data with missing value must have a 0 isbuyer, which is strongly correlated with missing values. My conclusion makes sense because in the real world, it is difficult to collect data from people without buying histories and analyze their behivaiors such as frequency. Moreover, some customer just buy once, so we cannot gain an insight about their buying frequency and habits, and in this case we also do not have enough information to make a prediction about their future buying behiviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Which variables are binary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['isbuyer', 'multiple_buy', 'multiple_visit', 'y_buy']\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "print([result.index[i] for i in range(0,len(result.index)) if result['number_distinct'][i]==2])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
