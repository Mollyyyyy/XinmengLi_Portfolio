Please enter your spark code as a response to each question listed below. Remember to provide your output as well.

>>> boats = spark.read.csv('boats.txt', schema='bid INT, bname STRING, color STRING')
>>> sailors = spark.read.json('sailors.json')
>>> reserves = spark.read.json('reserves.json')
>>> boats.createOrReplaceTempView('boats')
>>> sailors.createOrReplaceTempView('sailors')
>>> reserves.createOrReplaceTempView('reserves')

Question 1: 
How would you express the following computation using SQL instead of the object interface: sailors.filter(sailors.age < 30).select(sailors.sname)

Response:
#write spark code here
>>> res1 = spark.sql('SELECT sname FROM sailors WHERE age < 30')
>>> res1.show()
+-------+
|  sname|
+-------+
|   andy|
|horatio|
|horatio|
|    art|
+-------+



Question 2: How would you express the following using the object interface instead of SQL: spark.sql('SELECT * from reserves WHERE sid != 101')

Response:
#write spark code here
>>> res2 = reserves.filter(reserves.bid != 101)
>>> res2.show()
+---+----------+---+
|bid|      date|sid|
+---+----------+---+
|102|2018-10-10| 22|
|103| 2018-8-10| 22|
|104| 2018-7-10| 22|
|102|2018-11-10| 31|
|103| 2018-11-6| 31|
|104|2018-11-12| 31|
|102|  2018-9-8| 64|
|103|  2018-9-8| 74|
+---+----------+---+




Question 3: Using SQL and (multiple) inner joins, in a single query, how many distinct boats did each sailor reserve? The resulting DataFrame should include the sailor's id, name, and the count of distinct boats. (Hint: you may need to use first(...) aggregation function on some columns.) Provide both your query and the resulting DataFrame in your response to this question.

Response:
#write spark code here
>>> res3 = spark.sql('SELECT temp.sid,first(temp.sname) sname,COUNT(DISTINCT temp.bname) FROM (SELECT r.sid, s.sname, b.bname FROM sailors s INNER JOIN reserves r ON s.sid=r.sid INNER JOIN boats b on r.bid=b.bid) temp GROUP BY temp.sid')
>>> res3.show()
+---+-------+---------------------+                                             
|sid|  sname|count(DISTINCT bname)|
+---+-------+---------------------+
| 22|dusting|                    3|
| 31| lubber|                    3|
| 74|horatio|                    1|
| 64|horatio|                    1|
+---+-------+---------------------+




Question 4: Repeating the analysis from Lab2, implement a query using Spark which finds for each artist ID, the maximum track year, average track duration, and number of terms applied to the artist. What are the results for the ten artists with the longest average track durations? Include both your query code and resulting DataFrame in your response.

Response:
>>> artist_term = spark.read.csv('artist_term.csv',schema='artistID STRING,term STRING')
>>> tracks = spark.read.csv('tracks.csv',schema='trackID STRING,title STRING,release STRING,year INT,duration DOUBLE,artistID STRING')
>>> artist_term.createOrReplaceTempView('artist_term')
>>> tracks.createOrReplaceTempView('tracks')
#write spark code here
#implement a query using Spark which finds for each artist ID, the maximum track year, average track duration, and number of terms applied to the artist.
>>> res4 = spark.sql('SELECT  tracks.artistID, max(tracks.year), avg(tracks.duration), count(artist_term.term) FROM tracks LEFT JOIN artist_term ON tracks.artistID = artist_term.artistID GROUP BY tracks.artistID')
>>> res4.show()
+------------------+---------+------------------+-----------+                   
|          artistID|max(year)|     avg(duration)|count(term)|
+------------------+---------+------------------+-----------+
|AR5G69O1187B994CBC|     2006| 439.0656700000002|         26|
|AR64G1S1187FB4ACBF|        0|         220.57751|          6|
|AR66H0N1187B9AE91E|     2008| 230.4430833333333|        105|
|AR6JBG91187B98FFA5|     2006|327.75791499999997|          6|
|AR6PTTJ1187B991754|     2001|196.29146400000005|        130|
|AR7M2WZ1187B98A517|     1971| 153.9515780952382|        126|
|AR7OJQL11C8A414C9E|     2007|224.06224200000003|         20|
|AR7OX411187B9B1FDE|     2001| 284.3467583333331|        114|
|AR7RACU1187B99AD41|        0|296.56771000000003|          4|
|AR7SF1N1187B9A91D1|        0| 224.0091243333332|        150|
|AR8360R1187FB47C18|        0| 306.6945133333334|         27|
|AR83GCY1187B9AD949|     2007|115.99366599999988|         80|
|AR85RD81187FB5680F|     2005|239.41004999999984|        285|
|AR8IQZ81187FB54AEE|     2009|272.62879058823535|         51|
|AR8ISE21187B98F65F|     2009|200.78415000000004|         63|
|AR8JQ521187FB491AA|     2003| 157.9985680000001|         45|
|AR9AWNF1187B9AB0B4|     2008| 285.0659344186052|        774|
|AR9IVLJ1187B9B4DEA|     1996|327.19366900000074|        190|
|AR9WL321187B9A32D3|        0| 432.2868933333328|         54|
|ARA2BJX1187B998268|     2010| 261.6576693333326|        255|
+------------------+---------+------------------+-----------+
only showing top 20 rows

#results for the ten artists with the longest average track durations
>>> res4 = spark.sql('SELECT  tracks.artistID, max(tracks.year), avg(tracks.duration), count(artist_term.term) FROM tracks LEFT JOIN artist_term ON tracks.artistID = artist_term.artistID GROUP BY tracks.artistID ORDER BY avg(tracks.duration) DESC  LIMIT 10')
>>> res4.show()
+------------------+---------+------------------+-----------+                   
|          artistID|max(year)|     avg(duration)|count(term)|
+------------------+---------+------------------+-----------+
|ARJRKGN12420781485|        0|        3032.58077|          0|
|ARGDNIE1269FCD12AF|        0|        3030.62159|          0|
|ARFIKPQ1272BCD1FD4|        0|        3027.17342|          0|
|ARHDNFW11F4C83BECD|        0|        3026.75546|          0|
|ARIAXFE11F50C50923|        0|        3026.57261|          1|
|ARIV4271187B9B824F|        0| 3025.175060000001|         16|
|ARBNOH41187FB5B059|        0|3024.6134200000006|          7|
|ARBTWFL122988F01AF|        0|        3022.28853|          1|
|ARYDSAU1187FB39228|        0|         3007.4771|          4|
|ARUV9R01187FB3A240|        0| 3006.588929999999|         19|
+------------------+---------+------------------+-----------+




Question 5: Create a query that finds the number of distinct tracks associated (through artistID) to each term. Modify this query to return only the top 10 most popular terms, and again for the bottom 10. Include each query in your response. What are the 10 most and least popular terms?

Response:
#write spark code here
#finds the number of distinct tracks associated (through artistID) to each term
>>> res5 = spark.sql('SELECT COUNT(DISTINCT trackID),term FROM (SELECT t.trackID,a.term from tracks t RIGHT JOIN artist_term a ON t.artistID = a.artistID) GROUP BY term')
>>> res5.show(20,False)
+-----------------------+---------------------------+                           
|count(DISTINCT trackID)|term                       |
+-----------------------+---------------------------+
|2930                   |adult contemporary         |
|22102                  |singer-songwriter          |
|5483                   |melodic                    |
|1850                   |lyrical                    |
|752                    |anime                      |
|189                    |gramusels bluesrock        |
|126                    |indie music                |
|335                    |german metal               |
|1851                   |poetry                     |
|18                     |electronica latinoamericana|
|53                     |swedish hip hop            |
|26                     |oc remix                   |
|59                     |medwaybeat                 |
|24                     |haldern 2008               |
|108                    |traditional metal          |
|26                     |priority                   |
|88                     |french electro             |
|6                      |polish electronic          |
|58                     |indigenous                 |
|9                      |swedish black metal        |
+-----------------------+---------------------------+
only showing top 20 rows

#top 10 most popular terms
>>> res5 = spark.sql('SELECT COUNT(DISTINCT trackID),term FROM (SELECT t.trackID,a.term from tracks t RIGHT JOIN artist_term a ON t.artistID = a.artistID) GROUP BY term ORDER BY COUNT(DISTINCT trackID) DESC  LIMIT 10')
>>> res5.show()
+-----------------------+----------------+                                      
|count(DISTINCT trackID)|            term|
+-----------------------+----------------+
|                  86469|            rock|
|                  69971|      electronic|
|                  68682|             pop|
|                  44282|alternative rock|
|                  42888|         hip hop|
|                  42358|            jazz|
|                  40870|   united states|
|                  37361|     alternative|
|                  35589|        pop rock|
|                  34873|           indie|
+-----------------------+----------------+

The top 10 most popular terms are rock, electronic, pop, alternative rock, hip hop, jazz, united states, alternative, pop rock, indie.

#bottom 10 popular terms
>>> res5 = spark.sql('SELECT COUNT(DISTINCT trackID),term FROM (SELECT t.trackID,a.term from tracks t RIGHT JOIN artist_term a ON t.artistID = a.artistID) GROUP BY term ORDER BY COUNT(DISTINCT trackID)  LIMIT 10')
>>> res5.show()
+-----------------------+------------------+                                    
|count(DISTINCT trackID)|              term|
+-----------------------+------------------+
|                      0|    pixieland band|
|                      0|    icelandic rock|
|                      0|     simerock 2008|
|                      0|   milled pavement|
|                      0|     salsa boricua|
|                      0|   avebury records|
|                      0|         polyphony|
|                      0|         metalgaze|
|                      0|massachusetts rock|
|                      0|     galante music|
+-----------------------+------------------+

The 10 least popular terms are pixieland band, icelandic rock, simerock 2008, milled pavement, salsa boricu, avebury record, polyphony, metalgaze, massachusetts rock, galante music. In fact, there are more than 10 terms associated with no track i.e. COUNT(DISTINCT trackID)=0. Those terms without associated tracks are all the bottom popular terms. Since we are not required to rank the term in lexicographic order, any 10 terms associated with zero track can be regarded as the bottom 10 popular terms.

Question 6: Repeat questions 4 and 5, but now using the large versions of the CSV files stored at hdfs:/user/bm106/pub/artist_term_large.csv and hdfs:/user/bm106/pub/tracks_large.csv. Report the resulting DataFrames in your response. Did you have to change any of your analysis code, and if so, what?

Response:
#write spark code here
>>> artist_term = spark.read.csv('hdfs:/user/bm106/pub/artist_term_large.csv',schema='artistID STRING,term STRING')
>>> tracks = spark.read.csv('hdfs:/user/bm106/pub/tracks_large.csv',schema='trackID STRING,title STRING,release STRING,year INT,durati
on DOUBLE,artistID STRING')
>>> artist_term.createOrReplaceTempView('artist_term')
>>> tracks.createOrReplaceTempView('tracks')

#repeat questions 4
>>> res4 = spark.sql('SELECT  tracks.artistID, max(tracks.year), avg(tracks.duration), count(artist_term.term) FROM tracks LEFT JOIN a
rtist_term ON tracks.artistID = artist_term.artistID GROUP BY tracks.artistID')
>>> res4.show()
+------------------+---------+------------------+-----------+
|          artistID|max(year)|     avg(duration)|count(term)|
+------------------+---------+------------------+-----------+
|AR5G69O1187B994CBC|     2006|453.54621333333347|         81|
|AR64G1S1187FB4ACBF|        0|220.57751000000005|         18|
|AR66H0N1187B9AE91E|     2008|216.96646147058868|        612|
|AR6JBG91187B98FFA5|     2006|336.57424166666635|         66|
|AR6PTTJ1187B991754|     2001| 202.2165583999996|        675|
|AR6VJF11187FB4A0B7|        0|          243.5522|         10|
|AR7M2WZ1187B98A517|     1971| 160.7600006666667|        630|
|AR7OJQL11C8A414C9E|     2007|226.53342416666658|        120|
|AR7OX411187B9B1FDE|     2001|268.15854230769037|       1222|
|AR7RACU1187B99AD41|        0|335.85112363636364|         11|
|AR7SF1N1187B9A91D1|        0|211.59242826666605|       1200|
|AR8360R1187FB47C18|     2005| 272.8169047368426|        361|
|AR83GCY1187B9AD949|     2008| 140.1945496000002|       1200|
|AR85RD81187FB5680F|     2005| 236.4251247916656|       2016|
|AR8IQZ81187FB54AEE|     2009| 259.8077756756753|        407|
|AR8ISE21187B98F65F|     2009| 216.5489337499995|        736|
|AR8JQ521187FB491AA|     2003| 149.0480952941183|        578|
|AR9AWNF1187B9AB0B4|     2009| 274.7475894117592|       6528|
|AR9IVLJ1187B9B4DEA|     2006|347.10158666666723|       1764|
|AR9WL321187B9A32D3|        0| 426.5981363636392|        286|
+------------------+---------+------------------+-----------+
only showing top 20 rows

#results for the ten artists with the longest average track durations
>>> res4 = spark.sql('SELECT  tracks.artistID, max(tracks.year), avg(tracks.duration), count(artist_term.term) FROM tracks LEFT JOIN artist_term ON tracks.artistID = artist_term.artistID GROUP BY tracks.artistID ORDER BY avg(tracks.duration) DESC  LIMIT 10')
>>> res4.show()
+------------------+---------+------------------+-----------+
|          artistID|max(year)|     avg(duration)|count(term)|
+------------------+---------+------------------+-----------+
|ARCRQDC1272BA831EB|        0|        3033.44281|          0|
|ARJRKGN12420781485|        0|        3032.58077|          0|
|ARI4ARP1187FB50847|        0|         3032.5024|         13|
|ARKIGPF1187B98BD79|        0|3030.9089299999996|         15|
|ARGDNIE1269FCD12AF|        0|        3030.62159|          0|
|ARG62WR1187FB461BC|        0|3030.1775100000004|          9|
|ARNHB3M1187B98B512|        0|        3029.08036|         12|
|ARMDCV21187B9B13AD|        0| 3027.722000000001|         17|
|ARFIKPQ1272BCD1FD4|        0|        3027.17342|          0|
|ARHDNFW11F4C83BECD|        0|        3026.75546|          0|
+------------------+---------+------------------+-----------+

#repeat questions 5
>>> res5 = spark.sql('SELECT COUNT(DISTINCT trackID),term FROM (SELECT t.trackID,a.term from tracks t RIGHT JOIN artist_term a ON t.artistID = a.artistID) GROUP BY term')
>>> res5.show(20,False)
+-----------------------+---------------------------+
|count(DISTINCT trackID)|term                       |
+-----------------------+---------------------------+
|152831                 |singer-songwriter          |
|21956                  |adult contemporary         |
|2227                   |german metal               |
|12408                  |poetry                     |
|4132                   |anime                      |
|36747                  |melodic                    |
|1396                   |gramusels bluesrock        |
|871                    |traditional metal          |
|12894                  |lyrical                    |
|534                    |swedish hip hop            |
|249                    |oc remix                   |
|405                    |french electro             |
|150                    |persian traditional        |
|184                    |symphonic prog rock        |
|141                    |seattle band               |
|408                    |medwaybeat                 |
|94                     |electronica latinoamericana|
|782                    |indie music                |
|69                     |haldern 2008               |
|331                    |indigenous                 |
+-----------------------+---------------------------+
only showing top 20 rows

>>> res5 = spark.sql('SELECT COUNT(DISTINCT trackID),term FROM (SELECT t.trackID,a.term from tracks t RIGHT JOIN artist_term a ON t.artistID = a.artistID) GROUP BY term ORDER BY COUNT(DISTINCT trackID) DESC  LIMIT 10')
>>> res5.show()
+-----------------------+----------------+
|count(DISTINCT trackID)|            term|
+-----------------------+----------------+
|                 610884|            rock|
|                 484208|      electronic|
|                 474863|             pop|
|                 320506|alternative rock|
|                 301223|            jazz|
|                 295101|         hip hop|
|                 287360|   united states|
|                 262573|     alternative|
|                 248072|        pop rock|
|                 242083|           indie|
+-----------------------+----------------+
The top 10 popular terms are rock, electronic, pop, alternative rock, jazz, hip hop, united states, alternative, pop rock, indie. Compared with the result of Q5 on the small data file (i.e. rock, electronic, pop, alternative rock, hip hop, jazz, united states, alternative, pop rock, indie), the only difference is the order of jazz and hip hop. In the result of Q5 on the smaller file, hip hop is more popular than jazz.

>>> res5 = spark.sql('SELECT COUNT(DISTINCT trackID),term FROM (SELECT t.trackID,a.term from tracks t RIGHT JOIN artist_term a ON t.artistID = a.artistID) GROUP BY term ORDER BY COUNT(DISTINCT trackID) LIMIT 10')
>>> res5.show(20,False)
+-----------------------+---------------------+
|count(DISTINCT trackID)|term                 |
+-----------------------+---------------------+
|1                      |psychedelic country  |
|1                      |huapango             |
|1                      |polyphony            |
|1                      |third wave industrial|
|1                      |ney                  |
|1                      |milled pavement      |
|1                      |festival kinetik 2009|
|1                      |nonsense records     |
|1                      |electro french       |
|1                      |massachusetts rock   |
+-----------------------+---------------------+
The 10 bottom popular terms are psychedelic country, huapango, polyphony, third wave industrial, ney, milled pavement, festival kinetik 2009, nonsense records, electro french, massachusetts rock.

We do not need to change the code. The local code for Q4 and Q5 also works smoothly on dumbo.
